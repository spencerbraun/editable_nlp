{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d6ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3f6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862c5783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapped 8 modules using predicate:\n",
      "basic_block_predicate = lambda m: isinstance(m, torchvision.models.resnet.BasicBlock)\n",
      "\n",
      "Overriding existing `inner_params` implementation\n",
      "n default inner params: 17\n",
      "n inner params: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import vision.utils as utils\n",
    "import torchvision\n",
    "from alg.senn_conditional import ConditionalLinearWrapper\n",
    "\n",
    "ortho = utils.loadOTSModel(torchvision.models.resnet18, num_classes=10, pretrained=False)\n",
    "utils.prep_resnet_for_maml(ortho)\n",
    "basic_block_predicate = lambda m: isinstance(m, torchvision.models.resnet.BasicBlock)\n",
    "n_hidden = lambda m: m.conv2.weight.shape[0]\n",
    "ConditionalLinearWrapper.wrap_model(ortho, n_hidden, -3, basic_block_predicate)\n",
    "ortho.load_state_dict(torch.load('/iris/u/clin/code/editable_nlp/src/outputs/2021-05-18/21-40-59/models/finetune_epoch99_ts9999.2021-05-18.21-40-59'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff3fd554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64]) 0.8430989980697632\n",
      "torch.Size([64, 64]) 0.8345901966094971\n",
      "torch.Size([128, 128]) 2.041126012802124\n",
      "torch.Size([128, 128]) 3.076390027999878\n",
      "torch.Size([256, 256]) 5.9811248779296875\n",
      "torch.Size([256, 256]) 5.479241847991943\n",
      "torch.Size([512, 512]) 10.173482894897461\n",
      "torch.Size([512, 512]) 6.28060245513916\n"
     ]
    }
   ],
   "source": [
    "for p in ortho.phi():\n",
    "    mat = p.data\n",
    "    I = torch.eye(mat.shape[0], device=mat.device)\n",
    "    A = mat.triu(1) - mat.triu(1).permute(-1,-2)\n",
    "    weight = (I + A) @ (I - A).inverse()\n",
    "    diff = (weight - torch.eye(weight.shape[0])).norm().item()\n",
    "    print(weight.shape, diff)\n",
    "    # print(p.data.norm().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c361258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapped 8 modules for predicate <function <lambda> at 0x7fee2c510a60>\n",
      "Overriding existing `inner_params` implementation\n",
      "n default inner params: 17\n",
      "n inner params: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senn_50 = utils.loadOTSModel(torchvision.models.resnet18, num_classes=10, pretrained=False)\n",
    "utils.prep_resnet_for_maml(senn_50)\n",
    "basic_block_predicate = lambda m: isinstance(m, torchvision.models.resnet.BasicBlock)\n",
    "n_hidden = lambda m: m.conv2.weight.shape[0]\n",
    "ConditionalLinearWrapper.wrap_model(senn_50, n_hidden, -3, basic_block_predicate)\n",
    "senn_50.load_state_dict(torch.load('/iris/u/clin/code/editable_nlp/src/outputs/2021-05-18/15-28-22/models/finetune_epoch49_ts9999.2021-05-18.15-28-22'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bb86cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.047264099121094\n",
      "8.064950942993164\n",
      "11.475232124328613\n",
      "11.526585578918457\n",
      "16.387601852416992\n",
      "16.389881134033203\n",
      "23.38377571105957\n",
      "23.34132957458496\n"
     ]
    }
   ],
   "source": [
    "for p in senn_50.phi():\n",
    "#     mat = p.data\n",
    "#     diff = ((mat.T @ mat) - torch.eye(mat.shape[0])).norm().item()\n",
    "#     print(diff)\n",
    "    print(p.data.norm().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ebbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16239c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapped 8 modules using predicate:\n",
      "basic_block_predicate = lambda m: isinstance(m, torchvision.models.resnet.BasicBlock)\n",
      "\n",
      "Overriding existing `inner_params` implementation\n",
      "n default inner params: 17\n",
      "n inner params: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senn = utils.loadOTSModel(torchvision.models.resnet18, num_classes=10, pretrained=False)\n",
    "utils.prep_resnet_for_maml(senn)\n",
    "basic_block_predicate = lambda m: isinstance(m, torchvision.models.resnet.BasicBlock)\n",
    "n_hidden = lambda m: m.conv2.weight.shape[0]\n",
    "ConditionalLinearWrapper.wrap_model(senn, n_hidden, -3, basic_block_predicate)\n",
    "senn.load_state_dict(torch.load('/iris/u/clin/code/editable_nlp/src/outputs/2021-05-18/15-28-22/models/finetune_epoch49_ts9999.2021-05-18.15-28-22'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d69e2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) tensor(1.1388) tensor(0.8865)\n",
      "torch.Size([64]) tensor(1.1391) tensor(0.8797)\n",
      "torch.Size([128]) tensor(1.2611) tensor(0.7273)\n",
      "torch.Size([128]) tensor(1.2772) tensor(0.0977)\n",
      "torch.Size([256]) tensor(1.6191) tensor(0.2256)\n",
      "torch.Size([256]) tensor(1.6301) tensor(0.5316)\n",
      "torch.Size([512]) tensor(2.2300) tensor(0.0439)\n",
      "torch.Size([512]) tensor(2.7057) tensor(0.6069)\n"
     ]
    }
   ],
   "source": [
    "for p in senn.phi():\n",
    "    weight = p.data\n",
    "    U, S, Vh = torch.linalg.svd(weight)\n",
    "    print(S.shape, S.max(), S.min())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
