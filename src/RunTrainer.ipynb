{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thick-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import higher\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "miniature-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "from train_2 import EditTrainer\n",
    "from config import EditConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quality-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = utils.loadOTSModel()\n",
    "dataloader = utils.retrieveDataloader(\n",
    "        tokenizer, \n",
    "        bs=1, \n",
    "        dataset='train'\n",
    "    )\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ruled-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditConfig:\n",
    "    def __init__(self):\n",
    "        self.inner_lr = 1e-3\n",
    "        self.outer_lr = 1e-5\n",
    "        self.epochs = 1\n",
    "        self.max_training_samps = 2e4\n",
    "        self.n_edit_steps = 1\n",
    "        self.cedit = 1\n",
    "        self.cloc = 1\n",
    "\n",
    "        self.debug = True\n",
    "        self.model_save_pt = 2000\n",
    "        self.model_dir = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-moldova",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils\n",
    "\n",
    "from train_2 import EditTrainer\n",
    "from config import EditConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-legislature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-investment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blessed-european",
   "metadata": {},
   "source": [
    "## Testing Language Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "first-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Poppies and lupines are the primary flowers that dominate the green, lush rolling meadows in the spring to early summer, but in the late summer the hills turn gold and are covered with flowers such as the cluster-lily, gumweed, Mules ear, and farewell to spring. In shaded areas, one can expect to see thimbleberry and a variety of ferns growing. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "regulated-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Rather than having all of its functionality built into its core, Python was designed to be highly extensible (with modules). This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-genre",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "arabic-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = tokenizer.encode(text)\n",
    "token_out = tokenizer(\n",
    "    text\n",
    ")\n",
    "tokens, mask = map(\n",
    "    torch.tensor, \n",
    "    [token_out['input_ids'], token_out['attention_mask']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ranking-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([79])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "federal-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rather than having all of its functionality built into its core, Python was designed to be highly extensible (with modules). This compact modularity has made it particularly popular as a means of adding programmable\n"
     ]
    }
   ],
   "source": [
    "feed = tokens[:40]\n",
    "print(tokenizer.decode(token_list[:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efficient-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute and \", return_tensors=\"pt\")\n",
    "generation_output = model.generate(**inputs, return_dict_in_generate=True, output_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "essential-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedySearchDecoderOnlyOutput(sequences=tensor([[15496,    11,   616,  3290,   318, 13779,   290,   220, 17479,    13,\n",
       "           314,  1842,   683,   523,   881,    13,   314,  1842,   683,   523]]), scores=(tensor([[-43.4955, -46.0844, -46.9108,  ..., -57.7377, -51.5319, -48.3616]]), tensor([[-48.8799, -50.3510, -55.1450,  ..., -64.8533, -62.6215, -52.4255]]), tensor([[-67.7690, -65.9575, -67.5762,  ..., -76.5747, -74.8564, -60.7996]]), tensor([[-86.5862, -85.9131, -89.9283,  ..., -97.0860, -86.9367, -87.2296]]), tensor([[-66.0425, -67.5343, -71.4601,  ..., -75.1458, -72.8039, -67.9962]]), tensor([[-59.0425, -63.4027, -69.0216,  ..., -77.3129, -73.8313, -64.7133]]), tensor([[-60.0665, -62.8150, -68.4672,  ..., -72.5271, -70.3083, -63.8665]]), tensor([[-47.8266, -52.4544, -58.7991,  ..., -65.4726, -64.2974, -52.0334]]), tensor([[-71.7299, -70.1800, -72.2610,  ..., -82.0179, -80.4628, -63.5811]]), tensor([[-86.2451, -85.7662, -90.2981,  ..., -97.1315, -86.9278, -86.6646]]), tensor([[-66.2329, -67.0229, -71.5159,  ..., -74.7966, -72.8139, -67.0762]]), tensor([[-65.1541, -69.3030, -75.6400,  ..., -81.9662, -78.9824, -69.9710]])), attentions=None, hidden_states=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "educational-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cardiac-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Rather than having all of its functionality built into its core, Python was designed to be highly extensible (with modules). This compact modularity has made\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dress-uniform",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATED SEQUENCE 1 ===\n",
      "Rather than having all of its functionality built into its core, Python was designed to be highly extensible (with modules). This compact modularity has made much of python less complex but it is also able to do other things just as easy for anyone t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Rather than having all of its functionality built into its core, Python was designed to be highly extensible (with modules). This compact modularity has made much of python less complex but it is also able to do other things just as easy for anyone t']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text = text\n",
    "encoded_prompt = tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "input_ids = encoded_prompt\n",
    "\n",
    "output_sequences = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=20 + len(encoded_prompt[0]),\n",
    "    temperature=1.2,\n",
    "#     top_k=args.k,\n",
    "#     top_p=args.p,\n",
    "    repetition_penalty=1,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "\n",
    "# Remove the batch dimension when returning multiple sequences\n",
    "if len(output_sequences.shape) > 2:\n",
    "    output_sequences.squeeze_()\n",
    "\n",
    "generated_sequences = []\n",
    "\n",
    "for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "    print(\"=== GENERATED SEQUENCE {} ===\".format(generated_sequence_idx + 1))\n",
    "    generated_sequence = generated_sequence.tolist()\n",
    "\n",
    "    # Decode text\n",
    "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # Remove all text after the stop token\n",
    "    text = text[: text.find('<|endoftext|>')]\n",
    "\n",
    "    # Add the prompt at the beginning of the sequence. Remove the excess text that was used for pre-processing\n",
    "    total_sequence = (\n",
    "        prompt_text + text[len(tokenizer.decode(encoded_prompt[0], clean_up_tokenization_spaces=True)) :]\n",
    "    )\n",
    "\n",
    "    generated_sequences.append(total_sequence)\n",
    "    print(total_sequence)\n",
    "\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "promotional-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt_text = text\n",
    "encoded_prompt = tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "input_ids = encoded_prompt\n",
    "\n",
    "output_sequences = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=20 + len(encoded_prompt[0]),\n",
    "    temperature=1.2,\n",
    "#     top_k=args.k,\n",
    "#     top_p=args.p,\n",
    "    repetition_penalty=1,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "affiliated-suffering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "tensor([  256, 34369,    13,  1320,   531,   532,   314,   836,   470,   892,\n",
      "         9599,   508, 14759, 11361,  1865,   815,   307,   379,   477, 32064,\n",
      "           13])\n",
      "tensor([ 256, 7834,  306,  284, 3551, 2438,  357,   72,   13,   68,   13, 3551,\n",
      "        6725,  326,  314, 1101, 1262,  287,  257, 2248,  737])\n",
      "tensor([ 256, 5430, 1223,  656,  663, 2779,  393,  655, 1804, 1243, 1088,  340,\n",
      "          13,  198,  198,  198, 3844,   11,  981,  428, 1244])\n",
      "tensor([  256,  7834,   278,   351, 11361,    13,   198,   198,   198,  1135,\n",
      "          550,  2904,  3066,   422,   262,  3726,   326,   356,   655,  2622,\n",
      "          284])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.size())\n",
    "for i in range(4):\n",
    "    print(output_sequences[i, 49:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "global-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SelfSampleTrainer(EditTrainer):\n",
    "    def __init__(self, config, dataloader, model_path=None):\n",
    "        super().__init__(config, dataloader, model_path) \n",
    "        \n",
    "        self.finetuned = utils.loadTrainedModel(\n",
    "            \"../models/finetune/gpt2_epoch0_ts10000.20210310.18.03.1615401990\", \n",
    "            tokenizer=False\n",
    "        )\n",
    "        self.finetuned.to(self.device)\n",
    "        \n",
    "    def genModelText(self, lm_tokens, edit_locs):\n",
    "        \n",
    "\n",
    "        input_ids = lm_tokens[:, :edit_locs.min()]\n",
    "        input_size = input_ids.size()[-1]\n",
    "        \n",
    "        self.model.eval()\n",
    "        print(\"generating\")\n",
    "        output_sequence = self.finetuned.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=input_size + 15,\n",
    "            temperature=1.2,\n",
    "            repetition_penalty=1.0,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=10,\n",
    "        )\n",
    "\n",
    "        edit_tokens = random.choice(output_sequence).unsqueeze(0)\n",
    "        edit_mask = torch.ones(edit_tokens.shape, dtype=torch.long)\n",
    "        edit_labels = torch.zeros(edit_tokens.shape, dtype=torch.long) - 100\n",
    "        edit_labels[:, input_size:] = edit_tokens[:, input_size:]\n",
    "        edit_labels = edit_labels.to(self.device)\n",
    "        edit_tokens, edit_mask = edit_tokens.to(self.device), edit_mask.to(self.device)\n",
    "\n",
    "        return edit_tokens, edit_mask, edit_labels\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "\n",
    "        if not self.config.debug:\n",
    "            torch.save(self.config, self.hyperspath)\n",
    "\n",
    "        self.model.train()\n",
    "        self.model.to(self.device)\n",
    "        opt = torch.optim.Adam(\n",
    "            self.model.parameters(), \n",
    "            self.config.outer_lr\n",
    "            )\n",
    "        \n",
    "        global_iter = 0\n",
    "        print(\"Starting Training\")\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            for train_step, (lm_data, edit_example, ent) in enumerate(self.data):\n",
    "            \n",
    "                lm_tokens, lm_mask = lm_data\n",
    "                lm_tokens, lm_mask = lm_tokens.to(self.device), lm_mask.to(self.device)\n",
    "                lm_labels = lm_tokens.masked_fill(lm_mask == 0, -100)\n",
    "                \n",
    "                ent_tokens = ent[0].flatten()\n",
    "                ent_tokens = ent_tokens[ent_tokens != 50256]\n",
    "                edit_locs = utils.locateEntityEdit(edit_example[0], ent_tokens)\n",
    "                if edit_locs.size == 0 or edit_locs.min() == 0:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    edit_tokens, edit_mask, edit_labels = self.genModelText(lm_tokens, edit_locs)\n",
    "                except RuntimeError:\n",
    "                    breakpoint()\n",
    "                \n",
    "                \n",
    "                inner_opt = torch.optim.SGD(\n",
    "                    self.model.transformer.h[-3:].parameters(), \n",
    "                    lr=self.config.inner_lr\n",
    "                    )\n",
    "\n",
    "                with higher.innerloop_ctx(\n",
    "                    self.model, \n",
    "                    inner_opt, \n",
    "                    copy_initial_weights=False, \n",
    "                    track_higher_grads=True\n",
    "                    ) as (fmodel, diffopt):\n",
    "                    \n",
    "                    for edit_step in range(self.config.n_edit_steps):\n",
    "\n",
    "                        loss = fmodel(\n",
    "                            edit_tokens, \n",
    "                            attention_mask=edit_mask,\n",
    "                            labels=edit_labels\n",
    "                        ).loss\n",
    "                        diffopt.step(loss)\n",
    "\n",
    "                    edit_out = fmodel(\n",
    "                        edit_tokens, \n",
    "                        attention_mask=edit_mask,\n",
    "                        labels=edit_labels\n",
    "                    )\n",
    "                    l_edit = edit_out.loss\n",
    "                    \n",
    "                    base_out = self.model(\n",
    "                        lm_tokens, \n",
    "                        attention_mask=lm_mask,\n",
    "                        labels=lm_labels\n",
    "                    )\n",
    "                    l_base = base_out.loss\n",
    "\n",
    "                    edited_base_out = fmodel(\n",
    "                        lm_tokens, \n",
    "                        attention_mask=lm_mask,\n",
    "                        labels=lm_labels\n",
    "                    )\n",
    "\n",
    "                    l_loc =  (\n",
    "                        F.softmax(base_out.logits.detach(), dim=-1) *\n",
    "                        (\n",
    "                            F.log_softmax(base_out.logits.detach(), dim=-1) - \n",
    "                            F.log_softmax(edited_base_out.logits, dim=-1)\n",
    "                        )).sum(-1).mean()\n",
    "                    \n",
    "                    total_loss = (\n",
    "                        l_base + \n",
    "                        self.config.cloc * l_loc  + \n",
    "                        self.config.cedit * l_edit\n",
    "                        )\n",
    "                    total_loss.backward()\n",
    "\n",
    "                    # accumulate grads \n",
    "                    if train_step % 5 == 0:\n",
    "                        opt.step()\n",
    "                        opt.zero_grad()\n",
    "                    \n",
    "                    global_iter += 1\n",
    "                    \n",
    "                    loss_dict = {\n",
    "                        \"l_base\": l_base, \"l_edit\": l_edit, \n",
    "                        \"l_loc\": l_loc, \"total\": total_loss\n",
    "                        }\n",
    "                    self.echo(train_step, **loss_dict)\n",
    "                    if not self.config.debug:\n",
    "                        self.tensorBoard(global_iter, **loss_dict)\n",
    "                        self.saveModel(self.model, train_step)\n",
    "\n",
    "                        if train_step % 1000 == 0:\n",
    "                            self.validateEditTraining()\n",
    "\n",
    "        if not self.config.debug:\n",
    "            self.saveModel(self.model, train_step)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "political-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 0; ', 'l_base 4.847848892211914; l_edit 4.031960487365723; l_loc 9.952959953807294e-05; total 8.87990951538086')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 1; ', 'l_base 4.275406360626221; l_edit 3.1473236083984375; l_loc 0.00022555608302354813; total 7.422955513000488')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 2; ', 'l_base 3.782113552093506; l_edit 4.284780979156494; l_loc 6.106802902650088e-05; total 8.06695556640625')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 3; ', 'l_base 5.968358039855957; l_edit 5.778411865234375; l_loc 8.791322761680931e-05; total 11.746857643127441')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 4; ', 'l_base 4.617933750152588; l_edit 4.105910778045654; l_loc 0.0001569620508234948; total 8.724000930786133')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 5; ', 'l_base 3.728123426437378; l_edit 4.264476299285889; l_loc 0.0002277493040310219; total 7.992827415466309')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 6; ', 'l_base 4.511284351348877; l_edit 3.8918631076812744; l_loc 3.718812149600126e-05; total 8.40318489074707')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 7; ', 'l_base 3.945984125137329; l_edit 3.4840424060821533; l_loc 0.00011122846626676619; total 7.430137634277344')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 8; ', 'l_base 3.847501754760742; l_edit 4.626814365386963; l_loc 0.0002939675759989768; total 8.474610328674316')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 9; ', 'l_base 4.346887111663818; l_edit 4.933980464935303; l_loc 1.8954173356178217e-05; total 9.28088665008545')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 10; ', 'l_base 3.5720832347869873; l_edit 3.741851806640625; l_loc 8.901715045794845e-05; total 7.314023971557617')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 12; ', 'l_base 4.4242401123046875; l_edit 4.504977703094482; l_loc 0.00032653138623572886; total 8.929544448852539')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 15; ', 'l_base 3.4372527599334717; l_edit 5.071290493011475; l_loc 0.00014113281213212758; total 8.508684158325195')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 16; ', 'l_base 4.045205116271973; l_edit 3.5713987350463867; l_loc 5.901257827645168e-05; total 7.616662979125977')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 17; ', 'l_base 3.884176254272461; l_edit 4.2924652099609375; l_loc 7.441438356181607e-05; total 8.176715850830078')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 18; ', 'l_base 4.451939105987549; l_edit 4.54489278793335; l_loc 7.86064556450583e-05; total 8.996910095214844')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 19; ', 'l_base 3.5563535690307617; l_edit 3.7011563777923584; l_loc 3.8504575059050694e-05; total 7.2575483322143555')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 20; ', 'l_base 3.904815673828125; l_edit 3.037069082260132; l_loc 0.00012207838881295174; total 6.942007064819336')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 21; ', 'l_base 3.9763643741607666; l_edit 4.373611927032471; l_loc 7.194503268692642e-05; total 8.350048065185547')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 22; ', 'l_base 4.702048301696777; l_edit 4.3300089836120605; l_loc 9.288084402214736e-05; total 9.032150268554688')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 23; ', 'l_base 4.378472805023193; l_edit 3.226142406463623; l_loc 0.00019204254203941673; total 7.604807376861572')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 24; ', 'l_base 4.426316261291504; l_edit 2.9725394248962402; l_loc 9.052864334080368e-05; total 7.398946285247803')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 25; ', 'l_base 4.154033184051514; l_edit 3.3741378784179688; l_loc 8.760294440435246e-05; total 7.528258800506592')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 26; ', 'l_base 4.826742649078369; l_edit 3.2457330226898193; l_loc 5.1771792641375214e-05; total 8.072527885437012')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 27; ', 'l_base 4.669022083282471; l_edit 3.006422281265259; l_loc 2.626604873512406e-05; total 7.675470352172852')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 28; ', 'l_base 4.381113529205322; l_edit 5.3278584480285645; l_loc 0.00037420407170429826; total 9.709346771240234')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 29; ', 'l_base 4.869408130645752; l_edit 3.8057005405426025; l_loc 5.38376480108127e-05; total 8.675162315368652')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 30; ', 'l_base 4.149905204772949; l_edit 5.066888809204102; l_loc 0.0003465033951215446; total 9.217140197753906')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 32; ', 'l_base 4.0102338790893555; l_edit 3.1304361820220947; l_loc 2.808983117574826e-05; total 7.140698432922363')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 33; ', 'l_base 4.764048099517822; l_edit 3.544593095779419; l_loc 0.0001973041071323678; total 8.308838844299316')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 34; ', 'l_base 3.658181667327881; l_edit 4.895082950592041; l_loc 7.969007856445387e-05; total 8.5533447265625')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 37; ', 'l_base 4.282776355743408; l_edit 4.813879489898682; l_loc 6.024364847689867e-05; total 9.096715927124023')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 38; ', 'l_base 5.005941390991211; l_edit 4.034594535827637; l_loc 0.00024233113799709827; total 9.040778160095215')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 39; ', 'l_base 4.160793781280518; l_edit 2.9221174716949463; l_loc 0.00010258512338623405; total 7.083013534545898')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 40; ', 'l_base 3.9224605560302734; l_edit 4.858457565307617; l_loc 0.00028054192080162466; total 8.781198501586914')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 41; ', 'l_base 4.024776935577393; l_edit 4.325339317321777; l_loc 0.00029076970531605184; total 8.350406646728516')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 43; ', 'l_base 4.384141445159912; l_edit 4.176210880279541; l_loc 0.0003270713787060231; total 8.56067943572998')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 46; ', 'l_base 3.539642810821533; l_edit 3.998319149017334; l_loc 0.0003028751234523952; total 7.538264751434326')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 47; ', 'l_base 4.310018539428711; l_edit 4.299783229827881; l_loc 5.600602526101284e-05; total 8.609857559204102')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 49; ', 'l_base 4.333138942718506; l_edit 4.740351676940918; l_loc 7.366617501247674e-05; total 9.073564529418945')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 51; ', 'l_base 3.76676082611084; l_edit 3.8159353733062744; l_loc 2.504743133613374e-05; total 7.58272123336792')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 52; ', 'l_base 4.971736907958984; l_edit 3.6805267333984375; l_loc 0.0001584748679306358; total 8.652421951293945')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 53; ', 'l_base 4.35655403137207; l_edit 2.973344326019287; l_loc 0.00017532965284772217; total 7.330073833465576')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 54; ', 'l_base 4.4922380447387695; l_edit 2.994445562362671; l_loc 0.00021938547433819622; total 7.486903190612793')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 55; ', 'l_base 4.211339473724365; l_edit 4.303797245025635; l_loc 2.632146788528189e-05; total 8.51516342163086')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 56; ', 'l_base 4.655278205871582; l_edit 3.7920455932617188; l_loc 0.00012461580627132207; total 8.44744873046875')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 57; ', 'l_base 3.7548792362213135; l_edit 5.236897945404053; l_loc 3.0249722840380855e-05; total 8.99180793762207')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 58; ', 'l_base 4.835113525390625; l_edit 4.584047317504883; l_loc 3.1140370992943645e-05; total 9.419191360473633')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 59; ', 'l_base 4.019800186157227; l_edit 4.237873077392578; l_loc 9.040355507750064e-05; total 8.257763862609863')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 61; ', 'l_base 3.6006174087524414; l_edit 3.459458827972412; l_loc 0.00011047662701457739; total 7.060186386108398')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 62; ', 'l_base 3.921640396118164; l_edit 4.932989120483398; l_loc 0.00017465860582888126; total 8.854804039001465')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 63; ', 'l_base 4.590113162994385; l_edit 3.6603739261627197; l_loc 6.826685421401635e-05; total 8.250555038452148')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 64; ', 'l_base 4.202213764190674; l_edit 3.5252580642700195; l_loc 5.8449124480830505e-05; total 7.727530479431152')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 65; ', 'l_base 5.569684028625488; l_edit 4.2437968254089355; l_loc 3.275422932347283e-05; total 9.81351375579834')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 66; ', 'l_base 4.485429763793945; l_edit 3.288452625274658; l_loc 0.0001297703420277685; total 7.774012088775635')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 67; ', 'l_base 3.8527817726135254; l_edit 4.331613063812256; l_loc 2.253658567497041e-05; total 8.184417724609375')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 69; ', 'l_base 4.649467945098877; l_edit 5.390839099884033; l_loc 0.0002832601312547922; total 10.040590286254883')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 70; ', 'l_base 3.32847261428833; l_edit 4.047585964202881; l_loc 0.00012693763710558414; total 7.376185417175293')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 71; ', 'l_base 4.309097766876221; l_edit 2.7772390842437744; l_loc 0.00031483039492741227; total 7.086651802062988')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 72; ', 'l_base 4.557061195373535; l_edit 4.41136360168457; l_loc 0.00010058205225504935; total 8.968524932861328')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 73; ', 'l_base 3.8135159015655518; l_edit 4.9638142585754395; l_loc 7.020533666945994e-05; total 8.777400016784668')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 74; ', 'l_base 3.8964343070983887; l_edit 3.850329637527466; l_loc 0.00015696111950092018; total 7.746920585632324')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 75; ', 'l_base 4.012128829956055; l_edit 4.725078105926514; l_loc 0.00020317191956564784; total 8.737409591674805')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 76; ', 'l_base 5.2391581535339355; l_edit 3.1008458137512207; l_loc 2.890418363676872e-05; total 8.340032577514648')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 77; ', 'l_base 3.7875313758850098; l_edit 4.1634321212768555; l_loc 0.00019793372484855354; total 7.9511613845825195')\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 0; TrainStep 78; ', 'l_base 3.467377185821533; l_edit 4.028688907623291; l_loc 0.00019779133435804397; total 7.4962639808654785')\n",
      "generating\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1129661d4358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfSampleTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEditConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-d599039a442e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcedit\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml_edit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                         )\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0;31m# accumulate grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = SelfSampleTrainer(EditConfig(), dataloader)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-second",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
